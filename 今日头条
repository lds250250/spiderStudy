import json
import re
from urllib.parse import urlencode

import requests
from requests.exceptions import RequestException

from bs4 import BeautifulSoup as bs


class Sprider():
    def __init__(self, offset, keyword):
        self.data = {
            'offset': offset,
            'format': 'json',
            'keyword': keyword,
            'autoload': 'true',
            'count': '20',
            'cur_tab': 3,
            'from': 'gallery'
        }
        self.url = (
            f'https://www.toutiao.com/search_content/?{urlencode(self.data)}')

    def __get_page_index(self):
        try:
            response = requests.get(self.url)
            if response.status_code == 200:
                return response.text
            return None
        except RequestException:
            print('请求失败')
            return None

    def __parse_page_index(self, html):
        data = json.loads(html)
        if data and 'data' in data.keys():
            for item in data.get('data'):
                yield item.get('article_url')

    def __get_page_detail(self, url):
        try:
            response = requests.get(url)
            if response.status_code == 200:
                return response.text
            return None
        except RequestException:
            print('请求详情失败', url)
            return None

    def __parse_page_detail(self, html, url):
        soup = bs(html, 'lxml')
        title = soup.select('title')[0].get_text()
        images_pattern = re.compile('parse\("(.*?)"\),', re.S)
        result = re.search(images_pattern, html)
        if result:
            data = json.loads(result.group(1).replace('\\', ''))
            if data and 'sub_images' in data.keys():
                sub_images = data.get('sub_images')
                images = [item.get('url') for item in sub_images]
                return {'title': title, 'url': url, 'images': images}

    def go(self):
        html = self.__get_page_index()
        for url in self.__parse_page_index(html):
            html = self.__get_page_detail(url)
            if html:
                result = self.__parse_page_detail(html, url)
                print(result)


if __name__ == '__main__':
    sprider = Sprider(0, '美女')
    sprider.go()
