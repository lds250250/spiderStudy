import json
import os
import re
from hashlib import md5
from json.decoder import JSONDecodeError
from multiprocessing import Pool
from urllib.parse import urlencode

import pymongo
import requests
from bs4 import BeautifulSoup as bs
from requests.exceptions import RequestException

from config import (GROUP_END, GROUP_START, KEYWORD, MONGO_DB, MONGO_TABLE,
                    MONGO_URL)


class Sprider():
    def __init__(self, offset, keyword):
        self.data = {
            'offset': offset,
            'format': 'json',
            'keyword': keyword,
            'autoload': 'true',
            'count': '20',
            'cur_tab': 3,
            'from': 'gallery'
        }
        self.url = (
            f'https://www.toutiao.com/search_content/?{urlencode(self.data)}')

    def __get_page_index(self):
        try:
            response = requests.get(self.url)
            if response.status_code == 200:
                return response.text
            return None
        except RequestException:
            print('请求失败')
            return None

    def __parse_page_index(self, html):
        try:
            data = json.loads(html)
            if data and 'data' in data.keys():
                for item in data.get('data'):
                    yield item.get('article_url')
        except JSONDecodeError:
            pass

    def __get_page_detail(self, url):
        try:
            response = requests.get(url)
            if response.status_code == 200:
                return response.text
            return None
        except RequestException:
            print('请求详情失败', url)
            return None

    def __parse_page_detail(self, html, url):
        soup = bs(html, 'lxml')
        title = soup.select('title')[0].get_text()
        images_pattern = re.compile('parse\("(.*?)"\),', re.S)
        result = re.search(images_pattern, html)
        if result:
            data = json.loads(result.group(1).replace('\\', ''))
            if data and 'sub_images' in data.keys():
                sub_images = data.get('sub_images')
                images = [item.get('url') for item in sub_images]
                for image in images:
                    self.__download_image(image)
                return {'title': title, 'url': url, 'images': images}

    def __download_image(self, url):
        print(f'正在下载 {url}')
        try:
            response = requests.get(url)
            if response.status_code == 200:
                self.__save_image(response.content)
            return None
        except RequestException:
            print('请求图片失败', url)
            return None

    def __save_image(self, content):
        file_path = f'{os.getcwd()}/{md5(content).hexdigest()}.jpg'
        if not os.path.exists(file_path):
            with open(file_path, 'wb') as f:
                f.write(content)
                f.close()

    def __save_to_mongo(self, result):
        if db[MONGO_TABLE].insert(result):
            print('存储到MongoDB成功', result)
            return True
        return False

    def go(self):
        html = self.__get_page_index()
        for url in self.__parse_page_index(html):
            html = self.__get_page_detail(url)
            if html:
                result = self.__parse_page_detail(html, url)
                self.__save_to_mongo(result)


if __name__ == '__main__':
    client = pymongo.MongoClient(MONGO_URL, connect=False)
    db = client[MONGO_DB]
    groups = [x * 20 for x in range(GROUP_START, GROUP_END)]
    pool = Pool()
    sprider = Sprider(groups, KEYWORD)
    pool.map(sprider.go())
